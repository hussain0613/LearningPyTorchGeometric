{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing link prediction with PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a 'custom' `decoder` function\n",
    "base: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([ # composite transform\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1) # 5% for validation, 10% for testing and the rest 85% for training\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(root='datasets/Cora', name='Cora', transform=transform)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_not_transformed = Planetoid(root='datasets/Cora', name='Cora')\n",
    "dataset_not_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[17948], edge_label_index=[2, 17948]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[1054], edge_label_index=[2, 1054]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 9501], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[2110], edge_label_index=[2, 2110]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # what are the `edge_label` and `edge_label_index`\n",
    "# i think, the `RandomLinkSplit` adds one negative samples for every positive samples in each of the returning graphs\n",
    "# `edge_index` holds the positive samples, used for message passing and encoding the graph structure\n",
    "# `edge_label_index` holds the positive+negative samples, used for decoding and calculating the loss i.e. supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[17948], edge_label_index=[2, 17948])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index == val_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.], device='cuda:0'), tensor([8974, 8974], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1776, 1405, 1645,  ..., 1002, 1886,  616],\n",
       "        [1623, 1053,  989,  ...,  200, 1752,  667]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1776, 1405, 1645,  ...,  571, 2531, 2154],\n",
       "        [1623, 1053,  989,  ..., 1570, 1026, 1224]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=1) # sum(subject_nodes * object_nodes)\n",
    "    \n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "    \n",
    "    def forward(self, data, neg_edge_index=None): \n",
    "        z = self.encode(data.x, data.edge_index)\n",
    "        \n",
    "        if not self.training:\n",
    "            return self.decode(z, data.edge_label_index).view(-1)\n",
    "\n",
    "        edge_label_index = torch.cat([\n",
    "            data.edge_label_index, neg_edge_index\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.decode(z, edge_label_index).view(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 128)\n",
       "  (conv2): GCNConv(128, 7)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(dataset.num_features, 128, dataset.num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17948])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    # NOTE: encoding is done on the original data, not on the data with negative samples, which is stored in `edge_label_index`\n",
    "    # and then before, decode, we calculate another new set of negative samples in each epoch and add them to the data\n",
    "    # so, here, we are not using the negative samples for encoding, but we are using them for decoding\n",
    "    # and we are calculating negative samples twice, once when loading data with `RandomLinkSplit` and once here witch `negative_sampling`\n",
    "    # the first negative samples are always the same, but the second ones are different in each epoch\n",
    "    \n",
    "\n",
    "    # calculating a new round of negative sampling for every every epoch\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index = train_data.edge_index,\n",
    "        num_nodes = train_data.num_nodes,\n",
    "        num_neg_samples = train_data.edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "    # edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
    "    #                               [0, 1, 2, 3]])\n",
    "    # negative_sampling(edge_index)\n",
    "    # tensor([[3, 0, 0, 3],\n",
    "    #   [2, 3, 2, 1]])\n",
    "    # is not a bad idea? we are teaching the model that (3, 2) is a negative sample, but what if (3, 2) is a positive sample in the test set or in reality?\n",
    "    # should we not corrupt the positive samples instead to create negative ones?\n",
    "    # or is this how negative sampling works? we are not sure if the negative samples are actually negative samples or not?\n",
    "\n",
    "    # concatenating the new neg samples with the existing samples\n",
    "    edge_label_index = torch.cat([\n",
    "        train_data.edge_label_index, \n",
    "        neg_edge_index\n",
    "    ], dim=-1)\n",
    "\n",
    "\n",
    "    # concatenating the labels(0s) for the new neg samples with the existing labels\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label, # 'main' labels\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1)) # 0s for the new neg samples\n",
    "    ], dim = 0)\n",
    "\n",
    "    # NOTE: Negative sample are only used for decoding, not for encoding\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    \n",
    "    loss = criterion(out, edge_label) # loss calculation\n",
    "    loss.backward() # backpropagation\n",
    "    optimizer.step() # weight update\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index = train_data.edge_index,\n",
    "        num_nodes = train_data.num_nodes,\n",
    "        num_neg_samples = train_data.edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label, \n",
    "        torch.zeros(neg_edge_index.size(1), dtype=torch.float, device=device)\n",
    "    ], dim=-1)\n",
    "\n",
    "    out = model(train_data, neg_edge_index)\n",
    "\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data: Data):\n",
    "    model.eval() # set the model to evaluation mode\n",
    "    z = model.encode(data.x, data.edge_index) # encode the data\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid() # decode the data\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy()) # calculate the roc auc score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test2(data: Data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6932, Val: 0.7518, Test: 0.7491\n",
      "Epoch: 002, Loss: 0.6969, Val: 0.7417, Test: 0.7287\n",
      "Epoch: 003, Loss: 0.6934, Val: 0.6607, Test: 0.6945\n",
      "Epoch: 004, Loss: 0.6932, Val: 0.6025, Test: 0.6352\n",
      "Epoch: 005, Loss: 0.6933, Val: 0.4786, Test: 0.4984\n",
      "Epoch: 006, Loss: 0.6934, Val: 0.4687, Test: 0.4788\n",
      "Epoch: 007, Loss: 0.6934, Val: 0.4761, Test: 0.4773\n",
      "Epoch: 008, Loss: 0.6934, Val: 0.4795, Test: 0.4815\n",
      "Epoch: 009, Loss: 0.6934, Val: 0.4839, Test: 0.4784\n",
      "Final Test: 0.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [   0,    1,    2,  ..., 2705, 2706, 2707]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 10):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "final_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6933, Val: 0.5123, Test: 0.4744\n",
      "Epoch: 002, Loss: 0.6933, Val: 0.5165, Test: 0.5072\n",
      "Epoch: 003, Loss: 0.6932, Val: 0.5145, Test: 0.5091\n",
      "Epoch: 004, Loss: 0.6932, Val: 0.5109, Test: 0.5175\n",
      "Epoch: 005, Loss: 0.6932, Val: 0.5109, Test: 0.5191\n",
      "Epoch: 006, Loss: 0.6932, Val: 0.5110, Test: 0.5191\n",
      "Epoch: 007, Loss: 0.6932, Val: 0.5126, Test: 0.5192\n",
      "Epoch: 008, Loss: 0.6932, Val: 0.5181, Test: 0.5192\n",
      "Epoch: 009, Loss: 0.6932, Val: 0.4945, Test: 0.5210\n",
      "Final Test: 0.5192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [   0,    1,    2,  ..., 2705, 2706, 2707]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 10):\n",
    "    loss = train2()\n",
    "    val_auc = test2(val_data)\n",
    "    test_auc = test2(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "final_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the various 'utils' functions\n",
    "mainly `nagative_sampling`, `RandomLinkSplit` and `train_test_split_edges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 3], edge_index=[2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1, 2, 3], \n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12],\n",
    "    [13, 14, 15]\n",
    "])\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 2],\n",
    "    [1, 2, 0]\n",
    "])\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [2, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sampling(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 3, 3, 2, 4],\n",
       "        [3, 0, 1, 0, 1, 3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sampling(\n",
    "    edge_index = edge_index,\n",
    "    num_nodes = data.num_nodes, # 3\n",
    "    num_neg_samples = 6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[5, 3], edge_index=[2, 3], edge_label=[6], edge_label_index=[2, 6]),\n",
       " Data(x=[5, 3], edge_index=[2, 3], edge_label=[0], edge_label_index=[2, 0]),\n",
       " Data(x=[5, 3], edge_index=[2, 3], edge_label=[0], edge_label_index=[2, 0])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(num_val=0.05, num_test=0.1)(data)\n",
    "[train_data, val_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Installations\\JupyterNotebook\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 3], val_pos_edge_index=[2, 0], test_pos_edge_index=[2, 0], train_pos_edge_index=[2, 4], train_neg_adj_mask=[5, 5], val_neg_edge_index=[2, 0], test_neg_edge_index=[2, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split_edges(data.clone(), val_ratio=0.05, test_ratio=0.1) # in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 3], edge_index=[2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 1, 0, 3],\n",
       "        [1, 2, 0, 3, 4, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JupyterNotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
