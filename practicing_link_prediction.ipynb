{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing link prediction with PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a 'custom' `decoder` function\n",
    "base: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "# from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([ # composite transform\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1) # 5% for validation, 10% for testing and the rest 85% for training\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(root='datasets/Cora', name='Cora', transform=transform)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_not_transformed = Planetoid(root='datasets/Cora', name='Cora')\n",
    "dataset_not_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[17948], edge_label_index=[2, 17948]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[1054], edge_label_index=[2, 1054]),\n",
       " Data(x=[2708, 1433], edge_index=[2, 9501], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[2110], edge_label_index=[2, 2110]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # what are the `edge_label` and `edge_label_index`\n",
    "# i think, the `RandomLinkSplit` adds one negative samples for every positive samples in each of the returning graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8974], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[17948], edge_label_index=[2, 17948])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index == val_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.]), tensor([8974, 8974]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1867,  201,  598,  ...,  727,  722, 1399],\n",
       "        [2117,  598, 1003,  ...,  608, 1967,  977]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1867,  201,  598,  ..., 2448, 1013, 1359],\n",
       "        [2117,  598, 1003,  ..., 1067, 1661, 2480]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=1) # sum(subject_nodes * object_nodes)\n",
    "    \n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "    \n",
    "    def forward(self, data: Data): \n",
    "        z = self.encode(data.x, data.edge_index)\n",
    "        \n",
    "        if not self.training:\n",
    "            return self.decode(z, data.edge_label_index).view(-1)\n",
    "\n",
    "        # calculating a new set of negative samples\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index = train_data.edge_index,\n",
    "            num_nodes = train_data.num_nodes,\n",
    "            num_neg_samples = train_data.edge_label_index.size(1),\n",
    "            method='sparse'\n",
    "        )\n",
    "\n",
    "        # adding those negative sample to the data\n",
    "        edge_label_index = torch.cat([\n",
    "            train_data.edge_label_index, \n",
    "            neg_edge_index\n",
    "        ], dim=-1)\n",
    "\n",
    "        edge_label = torch.cat([\n",
    "            train_data.edge_label,\n",
    "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim = 0)\n",
    "\n",
    "        return self.decode(z, edge_label_index).view(-1)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 128)\n",
       "  (conv2): GCNConv(128, 7)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(dataset.num_features, 128, dataset.num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17948])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_label_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # calculating a new round of negative sampling for every every epoch\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index = train_data.edge_index,\n",
    "        num_nodes = train_data.num_nodes,\n",
    "        num_neg_samples = train_data.edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "\n",
    "    # adding concatenating the new neg sample with the existing samples\n",
    "    edge_label_index = torch.cat([\n",
    "        train_data.edge_label_index, \n",
    "        neg_edge_index\n",
    "    ], dim=-1)\n",
    "\n",
    "\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim = 0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    \n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the codes bellow this, are direct copy-paste, without reading anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data: Data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6302, Val: 0.8624, Test: 0.8547\n",
      "Epoch: 002, Loss: 0.6274, Val: 0.8647, Test: 0.8586\n",
      "Epoch: 003, Loss: 0.6283, Val: 0.8661, Test: 0.8607\n",
      "Epoch: 004, Loss: 0.6278, Val: 0.8675, Test: 0.8616\n",
      "Epoch: 005, Loss: 0.6270, Val: 0.8681, Test: 0.8632\n",
      "Epoch: 006, Loss: 0.6254, Val: 0.8688, Test: 0.8651\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JupyterNotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
